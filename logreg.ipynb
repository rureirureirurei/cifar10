{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marekpiotradamczyk/ml_uwr_22/blob/main/kmeans_deep_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it differs from the default solution? \n",
    "\n",
    "More smaller patches and denser patches extraction from images.\n",
    "Note that it takes significant time to execute all steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C          = 50000 # 1000 - 0.24, 5000 - 0.3432, 25000 - 0.3861\n",
    "PATCH_SIZE = 4\n",
    "patch_num  = 100000\n",
    "STRIDE     = 4\n",
    "k          = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & default imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T36fIpVCGGAt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sstats\n",
    "import multiprocessing as mp\n",
    "from sklearn import datasets\n",
    "import sklearn.linear_model\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import animation, pyplot, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import httpimport\n",
    "from os.path import join\n",
    "import os.path\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f6je-NQf810D",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q gdown httpimport\n",
    "![ -e cifar.npz ] || gdown 'https://drive.google.com/uc?id=1oBzZdtg2zNTPGhbRy6DQ_wrf5L5OAhNR' -O cifar.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XVdY0QLv9dAv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with np.load('cifar.npz') as data:\n",
    "    cifar_train_data = data['train_data']\n",
    "    cifar_train_labels = data['train_labels']\n",
    "    cifar_test_data = data['test_data']\n",
    "    cifar_test_labels = data['test_labels']\n",
    "\n",
    "\n",
    "def exists(file_path):\n",
    "    return os.path.isfile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "GoayFo-HlVXf",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_trn = cifar_train_data\n",
    "y_trn = cifar_train_labels\n",
    "X_tst = cifar_test_data\n",
    "y_tst = cifar_test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krVBYnbQS5Z_"
   },
   "source": [
    "# All in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class clf():\n",
    "      \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def contrast(self, image):\n",
    "        return (image-image.min())/(image.max() - image.min())\n",
    "\n",
    "    def normalize_patch(self, patch, eps=10):\n",
    "        return (patch - patch.mean())/np.sqrt(patch.var() + eps)\n",
    "\n",
    "    def whiten(self, X):\n",
    "        X_norm = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        cov = np.cov(X_norm, rowvar=False) \n",
    "        U,S,V = np.linalg.svd(cov)\n",
    "\n",
    "        X_zca = U.dot(np.diag(1.0/np.sqrt(S + 0.1))).dot(U.T).dot(X_norm.T).T\n",
    "        return X_zca\n",
    "\n",
    "    def centroids(self, data, k):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, random_state=0, verbose=False, n_init=1, max_iter=200, batch_size=10000)\n",
    "        kmeans.fit(data)\n",
    "        return kmeans.cluster_centers_\n",
    "    \n",
    "    def extract_patches(self, data):\n",
    "        patches = []\n",
    "        reshaped = data.reshape(-1,32,32,3)\n",
    "        n = int(patch_num / (32-PATCH_SIZE+1) ** 2 + 1)\n",
    "        for i in range(n):\n",
    "            for r in range(32-PATCH_SIZE+1):\n",
    "                for c in range(32-PATCH_SIZE+1):\n",
    "                    patch = reshaped[i][c:(c+PATCH_SIZE),r:(r+PATCH_SIZE)].flatten()\n",
    "                    patch_norm = self.normalize_patch(patch, eps=10)\n",
    "                    patches.append(patch_norm)\n",
    "\n",
    "        P = np.vstack(patches)\n",
    "        return self.whiten(P)\n",
    "    \n",
    "    def dist(self, x,y):\n",
    "        return np.sqrt((x - y).dot(x-y))\n",
    "\n",
    "    def create_patch_features(self, X):    \n",
    "        X_mapped_list_per_image = []\n",
    "        for i in range(X.shape[0]):\n",
    "            mapped_features = []\n",
    "            for r in range(0, 32-PATCH_SIZE+1, STRIDE):\n",
    "                for c in range(0, 32-PATCH_SIZE+1, STRIDE):\n",
    "                    patch = X[i].reshape(32,32,3)[c:(c+PATCH_SIZE),r:(r+PATCH_SIZE)].flatten()\n",
    "                    patch_norm = self.normalize_patch(patch, eps=0.01)\n",
    "                    mapped_features.append([dist(patch_norm, f) for f in filters_final])\n",
    "            X_mapped_list_per_image.append(np.vstack(mapped_features))\n",
    "        X_mapped = np.asarray(X_mapped_list_per_image).reshape(-1, ((32-PATCH_SIZE)//STRIDE+1)**2*filters_final.shape[0])\n",
    "        return X_mapped\n",
    "\n",
    "    def create_patch_features__vectorized(self, X):    \n",
    "        X_mapped_list_per_image = []\n",
    "        for i in range(X.shape[0]):\n",
    "            patches = image.extract_patches_2d(X[i], (PATCH_SIZE, PATCH_SIZE))\n",
    "            strided_patches = patches.reshape( 32-PATCH_SIZE+1 , 32-PATCH_SIZE+1, PATCH_SIZE, PATCH_SIZE, 3)[::STRIDE,::STRIDE,:,:,:]\n",
    "            strided_patches = strided_patches.reshape(((32-PATCH_SIZE)//STRIDE+1)**2, PATCH_SIZE * PATCH_SIZE * 3)\n",
    "            mapped_features = euclidean_distances(np.asarray([self.normalize_patch(patch, eps=0.01) for patch in strided_patches]), self.filters_final)\n",
    "            X_mapped_list_per_image.append(mapped_features.reshape(((32-PATCH_SIZE)//STRIDE+1)**2 * self.filters_final.shape[0]))\n",
    "        X_mapped = np.asarray(X_mapped_list_per_image)\n",
    "        return X_mapped\n",
    "\n",
    "    def normalize(self, data):\n",
    "        return (data - data.mean(axis=0))/data.std(axis=0)  \n",
    " \n",
    "    \n",
    "    def fit(self, X_trn, y_trn, k):\n",
    "        P_zca = self.extract_patches(X_trn)\n",
    "        self.filters_final = self.centroids(P_zca,k)\n",
    "        X_mapped_trn = self.create_patch_features__vectorized(X_trn)\n",
    "        X_mapped_trn_norm = self.normalize(X_mapped_trn)\n",
    "        self.model = LogisticRegression(random_state=0, max_iter=80, n_jobs=-1, verbose=False)\n",
    "        self.model.fit(X_mapped_trn_norm, y_trn.flatten());\n",
    "        \n",
    "        \n",
    "    def accuracy(self, X_tst, y_tst):\n",
    "        X_mapped_tst = self.create_patch_features__vectorized(X_tst)\n",
    "        X_mapped_tst_norm = self.normalize(X_mapped_tst)\n",
    "        y_tst_pred = self.model.predict(X_mapped_tst_norm)\n",
    "        return (y_tst.flatten() == y_tst_pred).mean()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4938\n"
     ]
    }
   ],
   "source": [
    "model = clf()\n",
    "model.fit(X_trn[:C], y_trn[:C], k) # todo make k global\n",
    "print(model.accuracy(X_tst[:C], y_tst[:C]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding optimal k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "esPqtlHSS5aU",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "cd063896-e55c-48b9-8de9-a74083c90ec2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "C          = 5000\n",
    "PATCH_SIZE = 6\n",
    "patch_num  = 100000\n",
    "STRIDE     = 8\n",
    "\n",
    "errs_k = {}\n",
    "\n",
    "for kroot in tqdm(range(2,32)):\n",
    "    k = kroot **2\n",
    "    model = clf()\n",
    "    model.fit(X_trn[:C], y_trn[:C], k)\n",
    "    errs_k[k] = model.accuracy(X_tst[:C], y_tst[:C])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(errs_k.keys(), errs_k.values())\n",
    "errs_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding optimal patch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C          = 5000\n",
    "patch_num  = 100000\n",
    "STRIDE     = 8\n",
    "\n",
    "errs_patch_size = {}\n",
    "\n",
    "for i in tqdm(range(2,30)):\n",
    "    PATCH_SIZE = i\n",
    "    model = clf()\n",
    "    model.fit(X_trn[:C], y_trn[:C], k)\n",
    "    errs_patch_size[PATCH_SIZE] = model.accuracy(X_tst[:C], y_tst[:C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(errs_patch_size.keys(), errs_patch_size.values())\n",
    "errs_patch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "C          = 5000\n",
    "patch_num  = 100000\n",
    "PATCH_SIZE = 4\n",
    "\n",
    "errs_stride = {}\n",
    "\n",
    "for i in tqdm(range(2,30)):\n",
    "    STRIDE = i\n",
    "    model = clf()\n",
    "    model.fit(X_trn[:C], y_trn[:C], 9)\n",
    "    errs_stride[STRIDE] = model.accuracy(X_tst[:C], y_tst[:C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(errs_stride.keys(), errs_stride.values())\n",
    "errs_stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
