{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/marekpiotradamczyk/ml_uwr_22/blob/main/kmeans_deep_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How it differs from the default solution? \n",
    "\n",
    "Here we are using a neural network instead of a logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data & default imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "T36fIpVCGGAt",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as sstats\n",
    "import multiprocessing as mp\n",
    "from sklearn import datasets\n",
    "import sklearn.linear_model\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import animation, pyplot, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import httpimport\n",
    "from os.path import join\n",
    "import os.path\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import image\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "!pip install -q gdown httpimport\n",
    "![ -e cifar.npz ] || gdown 'https://drive.google.com/uc?id=1oBzZdtg2zNTPGhbRy6DQ_wrf5L5OAhNR' -O cifar.npz\n",
    "\n",
    "with np.load('cifar.npz') as data:\n",
    "    X_trn = data['train_data']\n",
    "    y_trn = data['train_labels']\n",
    "    X_tst = data['test_data']\n",
    "    y_tst = data['test_labels']\n",
    "\n",
    "\n",
    "def exists(file_path):\n",
    "    return os.path.isfile(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krVBYnbQS5Z_"
   },
   "source": [
    "# All in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class clf():\n",
    "      \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def contrast(self, image):\n",
    "        return (image-image.min())/(image.max() - image.min())\n",
    "\n",
    "    def normalize_patch(self, patch, eps=10):\n",
    "        return (patch - patch.mean())/np.sqrt(patch.var() + eps)\n",
    "\n",
    "    def whiten(self, X):\n",
    "        X_norm = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        cov = np.cov(X_norm, rowvar=False) \n",
    "        U,S,V = np.linalg.svd(cov)\n",
    "\n",
    "        X_zca = U.dot(np.diag(1.0/np.sqrt(S + 0.1))).dot(U.T).dot(X_norm.T).T\n",
    "        return X_zca\n",
    "\n",
    "    def centroids(self, data, k):\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, random_state=0, verbose=False, n_init=1, max_iter=200, batch_size=10000)\n",
    "        kmeans.fit(data)\n",
    "        return kmeans.cluster_centers_\n",
    "    \n",
    "    def extract_patches(self, data):\n",
    "        patches = []\n",
    "        reshaped = data.reshape(-1,32,32,3)\n",
    "        n = int(patch_num / (32-PATCH_SIZE+1) ** 2 + 1)\n",
    "        for i in range(n):\n",
    "            for r in range(32-PATCH_SIZE+1):\n",
    "                for c in range(32-PATCH_SIZE+1):\n",
    "                    patch = reshaped[i][c:(c+PATCH_SIZE),r:(r+PATCH_SIZE)].flatten()\n",
    "                    patch_norm = self.normalize_patch(patch, eps=10)\n",
    "                    patches.append(patch_norm)\n",
    "\n",
    "        P = np.vstack(patches)\n",
    "        return self.whiten(P)\n",
    "    \n",
    "    def dist(self, x,y):\n",
    "        return np.sqrt((x - y).dot(x-y))\n",
    "\n",
    "    def create_patch_features(self, X):    \n",
    "        X_mapped_list_per_image = []\n",
    "        for i in range(X.shape[0]):\n",
    "            mapped_features = []\n",
    "            for r in range(0, 32-PATCH_SIZE+1, STRIDE):\n",
    "                for c in range(0, 32-PATCH_SIZE+1, STRIDE):\n",
    "                    patch = X[i].reshape(32,32,3)[c:(c+PATCH_SIZE),r:(r+PATCH_SIZE)].flatten()\n",
    "                    patch_norm = self.normalize_patch(patch, eps=0.01)\n",
    "                    mapped_features.append([dist(patch_norm, f) for f in filters_final])\n",
    "            X_mapped_list_per_image.append(np.vstack(mapped_features))\n",
    "        X_mapped = np.asarray(X_mapped_list_per_image).reshape(-1, ((32-PATCH_SIZE)//STRIDE+1)**2*filters_final.shape[0])\n",
    "        return X_mapped\n",
    "\n",
    "    def create_patch_features__vectorized(self, X):    \n",
    "        X_mapped_list_per_image = []\n",
    "        for i in range(X.shape[0]):\n",
    "            patches = image.extract_patches_2d(X[i], (PATCH_SIZE, PATCH_SIZE))\n",
    "            strided_patches = patches.reshape( 32-PATCH_SIZE+1 , 32-PATCH_SIZE+1, PATCH_SIZE, PATCH_SIZE, 3)[::STRIDE,::STRIDE,:,:,:]\n",
    "            strided_patches = strided_patches.reshape(((32-PATCH_SIZE)//STRIDE+1)**2, PATCH_SIZE * PATCH_SIZE * 3)\n",
    "            mapped_features = euclidean_distances(np.asarray([self.normalize_patch(patch, eps=0.01) for patch in strided_patches]), self.filters_final)\n",
    "            X_mapped_list_per_image.append(mapped_features.reshape(((32-PATCH_SIZE)//STRIDE+1)**2 * self.filters_final.shape[0]))\n",
    "        X_mapped = np.asarray(X_mapped_list_per_image)\n",
    "        return X_mapped\n",
    "\n",
    "    def normalize(self, data):\n",
    "        return (data - data.mean(axis=0))/data.std(axis=0)  \n",
    " \n",
    "    \n",
    "    def fit(self, X_trn, y_trn, k):\n",
    "        P_zca = self.extract_patches(X_trn)\n",
    "        self.filters_final = self.centroids(P_zca,k)\n",
    "        X_mapped_trn = self.create_patch_features__vectorized(X_trn)\n",
    "        X_mapped_trn_norm = self.normalize(X_mapped_trn)\n",
    "        \n",
    "        self.M = X_mapped_trn_norm.shape[1]\n",
    "        print(X_mapped_trn_norm.shape)\n",
    "        \n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(512, activation='relu', input_shape=(M,)))\n",
    "        self.model.add(Dense(512, activation='relu'))\n",
    "        self.model.add(Dense(10, activation='softmax')) \n",
    "\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        history = self.model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, y_test))\n",
    "        \n",
    "        self.model.fit(X_mapped_trn_norm, y_trn.flatten());\n",
    "        \n",
    "        \n",
    "    def accuracy(self, X_tst, y_tst):\n",
    "        X_mapped_tst = self.create_patch_features__vectorized(X_tst)\n",
    "        X_mapped_tst_norm = self.normalize(X_mapped_tst)\n",
    "        \n",
    "        test_loss, test_accuracy = model.evaluate(X_mapped_tst_norm, y_tst, verbose=0)\n",
    "        return test_accuracy      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m k          \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m clf()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mC\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trn\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mC\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# todo make k global\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39maccuracy(X_tst[:C], y_tst[:C]))\n",
      "Cell \u001b[0;32mIn[4], line 73\u001b[0m, in \u001b[0;36mclf.fit\u001b[0;34m(self, X_trn, y_trn, k)\u001b[0m\n\u001b[1;32m     71\u001b[0m P_zca \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_patches(X_trn)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_final \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentroids(P_zca,k)\n\u001b[0;32m---> 73\u001b[0m X_mapped_trn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_patch_features__vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_trn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m X_mapped_trn_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(X_mapped_trn)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m=\u001b[39m X_mapped_trn_norm\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 61\u001b[0m, in \u001b[0;36mclf.create_patch_features__vectorized\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     59\u001b[0m     strided_patches \u001b[38;5;241m=\u001b[39m patches\u001b[38;5;241m.\u001b[39mreshape( \u001b[38;5;241m32\u001b[39m\u001b[38;5;241m-\u001b[39mPATCH_SIZE\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m , \u001b[38;5;241m32\u001b[39m\u001b[38;5;241m-\u001b[39mPATCH_SIZE\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, PATCH_SIZE, PATCH_SIZE, \u001b[38;5;241m3\u001b[39m)[::STRIDE,::STRIDE,:,:,:]\n\u001b[1;32m     60\u001b[0m     strided_patches \u001b[38;5;241m=\u001b[39m strided_patches\u001b[38;5;241m.\u001b[39mreshape(((\u001b[38;5;241m32\u001b[39m\u001b[38;5;241m-\u001b[39mPATCH_SIZE)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mSTRIDE\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, PATCH_SIZE \u001b[38;5;241m*\u001b[39m PATCH_SIZE \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m     mapped_features \u001b[38;5;241m=\u001b[39m \u001b[43meuclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_patch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstrided_patches\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilters_final\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     X_mapped_list_per_image\u001b[38;5;241m.\u001b[39mappend(mapped_features\u001b[38;5;241m.\u001b[39mreshape(((\u001b[38;5;241m32\u001b[39m\u001b[38;5;241m-\u001b[39mPATCH_SIZE)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mSTRIDE\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_final\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     63\u001b[0m X_mapped \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X_mapped_list_per_image)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:328\u001b[0m, in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m Y_norm_squared\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;241m1\u001b[39m, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    323\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimensions for Y of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mY_norm_squared of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moriginal_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         )\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:369\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    366\u001b[0m     distances \u001b[38;5;241m=\u001b[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX\n\u001b[1;32m    371\u001b[0m     distances \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m@\u001b[39m b\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m--> 192\u001b[0m     \u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43missparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/ml/lib/python3.10/site-packages/scipy/sparse/_base.py:1301\u001b[0m, in \u001b[0;36misspmatrix\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1297\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1298\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m-> 1301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misspmatrix\u001b[39m(x):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \n\u001b[1;32m   1304\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, spmatrix)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "C          = 50000\n",
    "PATCH_SIZE = 8\n",
    "patch_num  = 10000\n",
    "STRIDE     = 8\n",
    "k          = 256\n",
    "\n",
    "model = clf()\n",
    "model.fit(X_trn[:C], y_trn[:C], k) # todo make k global\n",
    "print(model.accuracy(X_tst[:C], y_tst[:C]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "M = 32*32*3\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "X_train = keras.utils.normalize(X_train.reshape(-1, M))\n",
    "X_test = keras.utils.normalize(X_test.reshape(-1, M))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(M,)))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=20, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.normalize(X_test.reshape(-1, 32 * 32 * 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
